default:
  logger:
    log_level: "INFO"
  service:
    host: "0.0.0.0"
    port: 8282
    cert_file: "ssl_certs/localhost.crt"
    cert_key: "ssl_certs/localhost.key"
  chat_engine:
    model_root: "models"
    concurrent_limit: 1
    handler_search_path:
      - "src/handlers"
    # WebRTC configuration with graceful media handling
    turn_config:
      turn_provider: "turn_server"
      urls:
        - "stun:stun.l.google.com:19302"
        - "stun:stun1.l.google.com:19302"
      username: ""
      credential: ""
    handler_configs:
      RtcClient:
        module: client/rtc_client/client_handler_rtc
        connection_ttl: 300
        concurrent_limit: 1
        # Media handling settings
        auto_start_media: false
        require_media_permissions: false
        graceful_media_fallback: true
        enable_text_only_mode: true
        # Connection settings
        ice_connection_timeout: 30000
        peer_connection_timeout: 20000
        data_channel_timeout: 15000
        # Retry settings
        max_connection_attempts: 3
        connection_retry_delay: 2000
      SileroVad:
        enabled: True
        module: vad/silerovad/vad_handler_silero
        # VAD settings optimized for reliable detection
        speaking_threshold: 0.4
        start_delay: 1500
        end_delay: 3000
        buffer_look_back: 3000
        speech_padding: 512
        use_cpu: true
        num_threads: 2
        # Graceful handling
        fallback_on_error: true
        auto_restart_on_failure: true
        max_initialization_attempts: 3
      Edge_TTS:
        enabled: True
        module: tts/edgetts/tts_handler_edgetts
        voice: "en-US-JennyNeural"
        sample_rate: 16000
        # Audio output settings
        output_format: "pcm"
        chunk_size: 1024
        # Performance settings
        timeout: 20
        max_retries: 2
        cache_enabled: true
        # Graceful error handling
        fallback_voice: "en-US-AriaNeural"
        continue_on_tts_error: true
        audio_fallback_enabled: true
      LLMOpenAICompatible:
        enabled: True
        module: llm/openai_compatible/llm_handler_openai_compatible
        model_name: "qwen2.5vl"
        enable_video_input: False
        history_length: 15
        system_prompt: "You are a helpful AI assistant. Keep responses conversational and under 150 words. If you detect any technical issues, acknowledge them briefly and continue helping."
        api_url: "http://ollama:11434/v1"
        api_key: "ollama"
        # Response settings
        timeout: 25
        max_retries: 2
        temperature: 0.7
        max_tokens: 800
        stream: false
        # Connection reliability
        request_timeout: 30
        connection_timeout: 5
        read_timeout: 25
        # Error handling
        continue_on_error: true
        fallback_response: "I apologize, but I'm having a technical issue. Please try your message again."
        # Performance optimization
        enable_parallel_processing: false
        batch_size: 1
      # Disable all avatar handlers for stability
      LiteAvatar:
        enabled: False
        module: avatar/liteavatar/avatar_handler_liteavatar
      MuseTalk:
        enabled: False
      AvatarMuseTalk:
        enabled: False
      MiniCPMAvatar:
        enabled: False
      # Text-only fallback handler (if available)
      TextOnlyHandler:
        enabled: True
        fallback_mode: true
        always_available: true
