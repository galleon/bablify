version: '3.8'

services:
  open-avatar-chat-mac-m3:
    build:
      context: .
      dockerfile: Dockerfile.mac-m3
      args:
        CONFIG_FILE: config/chat_with_minicpm_mac_m3.yaml
    container_name: open-avatar-chat-mac-m3
    ports:
      - "8282:8282"
    volumes:
      - ./models:/root/open-avatar-chat/models
      - ./resource:/root/open-avatar-chat/resource
      - ./ssl_certs:/root/open-avatar-chat/ssl_certs
      - ./logs:/root/open-avatar-chat/logs
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
    environment:
      # Mac M3 optimizations
      - PYTORCH_ENABLE_MPS_FALLBACK=1
      - PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0
      - OMP_NUM_THREADS=8
      - MKL_NUM_THREADS=8
      - VECLIB_MAXIMUM_THREADS=8
      - NUMEXPR_NUM_THREADS=8
      - ACCELERATE_USE_CPU=1
      - TRANSFORMERS_CACHE=/root/open-avatar-chat/models/transformers_cache
      - HF_HOME=/root/open-avatar-chat/models/huggingface_cache
      # Memory optimizations for Mac M3
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
      - MALLOC_ARENA_MAX=4
      # Display support for macOS
      - DISPLAY=host.docker.internal:0
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8282/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '8.0'
        reservations:
          memory: 8G
          cpus: '4.0'
    networks:
      - avatar-chat-network

  # Optional: Redis for caching (recommended for Mac M3)
  redis-cache:
    image: redis:7-alpine
    container_name: redis-cache-mac-m3
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --maxmemory 1gb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    networks:
      - avatar-chat-network

volumes:
  redis-data:
    driver: local

networks:
  avatar-chat-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
